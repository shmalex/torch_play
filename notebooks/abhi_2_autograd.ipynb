{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this JN is base on the Abhishek Thakur video\n",
    "https://www.youtube.com/watch?v=Poc0X5fS9us&list=PL98nY_tJQXZln8spB5uTZdKN08mYGkOf2&index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.266433Z",
     "start_time": "2021-05-14T22:16:06.618048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd is used in backproprogation step when training NN so you have to calculate the gradients of error with respect to all different parameters and that's what autograd is doing. Automatic diffirentiation engine in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:53:42.844658Z",
     "start_time": "2021-05-14T19:53:42.837288Z"
    }
   },
   "source": [
    "declare 2 variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.271968Z",
     "start_time": "2021-05-14T22:16:07.268664Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([5.], requires_grad=True)\n",
    "b = torch.tensor([6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.280877Z",
     "start_time": "2021-05-14T22:16:07.273694Z"
    }
   },
   "outputs": [],
   "source": [
    "y = a **3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.288281Z",
     "start_time": "2021-05-14T22:16:07.282484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's image we are calcultating the error\\loss so we have to calculate $dy/da$ and $dy/db$\n",
    "\n",
    "\n",
    "$$dy/da = 3*a^2=75, a=5$$\n",
    "\n",
    "$$dy/db = -2b=-12, b=6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.294924Z",
     "start_time": "2021-05-14T22:16:07.290283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(a.grad, b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see the gradient for both variables are none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.310349Z",
     "start_time": "2021-05-14T22:16:07.297980Z"
    }
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.316086Z",
     "start_time": "2021-05-14T22:16:07.312478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 75.0\n",
      "b -12.0\n"
     ]
    }
   ],
   "source": [
    "print('a',a.grad.detach().numpy()[0])\n",
    "print('b',b.grad.detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very usefull when you build your own model. Let's define some simple linead regression model with pytorch. we need to define the weight matrix and bais, with random intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.321992Z",
     "start_time": "2021-05-14T22:16:07.317408Z"
    }
   },
   "outputs": [],
   "source": [
    "W = torch.randn(10,1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.329338Z",
     "start_time": "2021-05-14T22:16:07.323756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2094],\n",
       "         [-0.4348],\n",
       "         [ 0.8553],\n",
       "         [ 0.3755],\n",
       "         [-0.7616],\n",
       "         [ 1.6897],\n",
       "         [-0.4975],\n",
       "         [ 0.2032],\n",
       "         [ 1.2473],\n",
       "         [ 1.7229]], requires_grad=True),\n",
       " tensor([-0.1486], requires_grad=True))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit this model to the data, some random data sample, 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.335206Z",
     "start_time": "2021-05-14T22:16:07.330926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1391, 0.2523, 0.5938, 0.4682, 0.9976, 0.6367, 0.9696, 0.5509, 0.2865,\n",
       "         0.0723]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's build the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.340376Z",
     "start_time": "2021-05-14T22:16:07.336909Z"
    }
   },
   "outputs": [],
   "source": [
    "output = torch.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and define the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.346659Z",
     "start_time": "2021-05-14T22:16:07.342066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1762]], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 1 - output\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.352227Z",
     "start_time": "2021-05-14T22:16:07.348282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8238]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.356900Z",
     "start_time": "2021-05-14T22:16:07.354107Z"
    }
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.363673Z",
     "start_time": "2021-05-14T22:16:07.358439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1391],\n",
       "        [-0.2523],\n",
       "        [-0.5938],\n",
       "        [-0.4682],\n",
       "        [-0.9976],\n",
       "        [-0.6367],\n",
       "        [-0.9696],\n",
       "        [-0.5509],\n",
       "        [-0.2865],\n",
       "        [-0.0723]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.370960Z",
     "start_time": "2021-05-14T22:16:07.365128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T20:10:14.003631Z",
     "start_time": "2021-05-14T20:10:13.997359Z"
    }
   },
   "source": [
    "we have calculated the gradients for the model's weight vector. we would like to update the weight's accodinly. for that we will subract the gradients from weights but scaled by learning_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.374756Z",
     "start_time": "2021-05-14T22:16:07.372436Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the mathimatical operaton should not affect the gradients, so we need to swtich the torch special mode `no_grad` that disabled gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.380704Z",
     "start_time": "2021-05-14T22:16:07.377599Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    W = W - learning_rate * W.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T22:16:07.387651Z",
     "start_time": "2021-05-14T22:16:07.382617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2080],\n",
       "        [-0.4323],\n",
       "        [ 0.8612],\n",
       "        [ 0.3802],\n",
       "        [-0.7516],\n",
       "        [ 1.6961],\n",
       "        [-0.4878],\n",
       "        [ 0.2087],\n",
       "        [ 1.2502],\n",
       "        [ 1.7236]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each new iteration we need to clear the gradients and update the weights and repeat the calculations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
